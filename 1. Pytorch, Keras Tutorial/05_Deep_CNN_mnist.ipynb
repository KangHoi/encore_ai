{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"05_Deep_CNN_mnist","private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNLclR9BznY3yxKWflye+8R"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"l2UjP43vsLiH"},"source":["import torch\n","import torchvision\n","import torch.nn as nn \n","import numpy as np\n","import torchvision.transforms as transforms \n","import matplotlib.pyplot as plt\n","\n","#디버깅 모듈 설치\n","import pdb\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W1MNtvJKJ8sd"},"source":["#우리가 사용할 컴퓨터를 check하는 부분, cpu/gpu 지원받을지..\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","device"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eQksIp1hsM-1"},"source":["# 하이퍼파라미터 설정\n","\n","input_size = 784 # mnist는 28x28x1로 구성\n","hidden_size = 500 # 은닉층의 unit 수\n","num_classes = 10 # 카테고리 개수\n","num_epochs = 5\n","batch_size = 100\n","learning_rate = 0.001\n","\n","# dataset 로딩 - 2개의 과정을 거친다\n","# train_dataset, test_dataset 데이터 로딩 1단계\n","train_dataset = torchvision.datasets.MNIST(root='../../data',\n","                                           train = True, #traindataset만 저장\n","                                           transform = transforms.ToTensor(),\n","                                           download = True) #traindataset을 스케일링하여 다운로드하겠다.\n","test_dataset = torchvision.datasets.MNIST(root='../../data',\n","                                           train = False, #test_dataset만 저장, test옵션은 따로 없음.\n","                                           transform = transforms.ToTensor())\n","\n","# 데이터 로딩 2단계.. BatchSize 이용\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size = batch_size,\n","                                           shuffle =True)\n","\n","# 100개씩 쪼개서 저장..\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                           batch_size = batch_size,\n","                                           shuffle =False) #테스트는 학습이아니므로 shuffle 필요 없다."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ml6p2CXvsUvM"},"source":["## Convolution NeuralNet Model 생성"]},{"cell_type":"code","metadata":{"id":"ak09Jk2asOgf"},"source":["class ConvNet(nn.Module):\n","  def __init__(self, num_classes=10):\n","    super(ConvNet, self).__init__()\n","    self.layer1 =nn.Sequential(\n","        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=2),\n","        nn.ReLU())\n","    \n","    self.layer2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","    self.layer3 = nn.Sequential(\n","        nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n","        nn.ReLU())\n","    \n","    self.layer4 = nn.MaxPool2d(kernel_size=2, stride=2)\n","    self.layer5 = nn.Linear(7*7*32, num_classes)\n","\n","  def forward(self, x):\n","\n","    # pdb.set_trace() # 2.디버깅\n","        # n : 다음 라인 가르킨다.\n","        # x.size, out.size  등 크기 확인 필요\n","\n","     out = self.layer1(x)\n","     out = self.layer2(out)\n","     out = self.layer3(out)\n","     out = self.layer4(out)\n","     out = out.reshape(out.size(0),-1)\n","     out = self.layer5(out)\n","\n","     return out\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"67MNva5QwW81"},"source":["model = ConvNet(num_classes).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VcdiFLPow1p6"},"source":["loss_function = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M4Ce7EssxIJB"},"source":["total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # pdb.set_trace() # 1. 디버깅.. 주석으로 막아두고 후에 사용.. outputs에서 호출되며 실행 \n","         \n","        # l : pdb로 어느부분을 디버깅 하려 하는지 알 수 있음.. 호출되는 함수인 forward가 나타남.\n","        # images.size(), images.shape : 이미지 사이즈 알아보기([batch_size, channel, height, width])\n","        # labels.size() : 라벨의 사이즈 알 수 있다.\n","        # labels : 라벨을 전부 뽑는다.\n","        # quit, q : 빠져나온다. 빠져나오면서 error 나오지만 신경 안써도됨.\n","        \n","\n","        \n","\n","        outputs = model(images) # =model.forward(images)...모델에 입력값을 넣어 예측값을 반환. 이때 forward함수 호출.\n","        \n","        loss = loss_function\n","\n","        # pdb.set_trace() #3.디버깅\n","            # loss값 확인 가능. loss.item()..\n","        n(outputs, labels)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if(i+1) % 100 ==0:\n","            print('Epoch[{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hf1lrEaWx78w"},"source":["model.eval() # 테스트모델이다..라는 의미\n","with torch.no_grad(): # 실제로 학습할 필요가 없으면 no.grad()구문을 넣어준다... no gradiation.. 편미분 안하겠다.\n","    correct = 0\n","    total = 0\n","    for images, labels in test_loader: # 인덱스를 굳이 안받아도 되니깐 enumeratorr가 빠졌다.\n","        images = images.to(device) #한줄로 죽 펼친 다음에 입력받아서\n","        labels = labels.to(device) # 라벨도 마찬가지로\n","        outputs = model(images) #모델에 넣고\n","        _, predicted = torch.max(outputs.data, 1)\n","        # total은 푼 문제, correct는 맞춘 문제수..이런식으로 카운팅이 들어간다\n","     \n","        total += labels.size(0) \n","        correct += (predicted == labels).sum().item()\n","        print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zgaFUTvpyrl1"},"source":["images.size()\n","images[0,0].size()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QwQsJMU7T9j3"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","idx = 12\n","image = np.array(images[idx,0].detach().cpu()) #detach().. 연산에서 분리. gpu에서 내려줘야하므로 .cpu() 사용\n","label = labels[idx].item()\n","label\n","pred = predicted[idx].item()\n","pred\n","\n","plt.imshow(image * 255) # tensor로 scale 되어있어서 원래 이미지 픽셀값으로 되돌린다.\n","print('Label : ', label)\n","print('Predict : ', predicted)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4me3M-gtUrYT"},"source":["for idx in range(30):\n","    image = np.array(images[idx,0].detach().cpu())\n","    label = labels[idx].item()\n","    pred = predicted[idx].item()\n","    plt.figure()\n","    plt.title(f'Label:{label} Pred:{pred}')\n","    plt.imshow(image * 255)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mItaU1G4VpqB"},"source":[""],"execution_count":null,"outputs":[]}]}