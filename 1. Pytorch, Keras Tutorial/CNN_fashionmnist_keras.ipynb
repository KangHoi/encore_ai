{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_fashionmnist_keras.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNskD3UGKj41/aE0E12ClZF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Mxr2MYLupboQ"},"source":["###1. padding = 'valid', epoch=20"]},{"cell_type":"code","metadata":{"id":"RuxWCPetlmkz"},"source":["import numpy as np\n","from keras import datasets\n","from keras import models, layers\n","from keras.utils import np_utils\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","\n","from keras import  backend\n"," \n","\n","# 1. DataLoader\n","(X_train, y_train),(X_test, y_test)=keras.datasets.fashion_mnist.load_data()\n","\n","# 2. 데이타 입력전 전처리과정 ---\n","# 1) 1차원으로 펼치기  2) /255   3)원핫인코딩\n","\n","L,H,W = X_train.shape # 3차원으로 출력된다...60000, 28, 28\n","\n","\n","# 전처리 1)\n","channel=backend.image_data_format()\n","channel\n","\n","if backend.image_data_format =='channels_first':\n","  X_train = X_train.reshape(X_train.shape[0],1, H, W) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], 1, H, W)\n","  input_shape = (1, H, W) #채널이 앞으로 간다\n","else:\n","  X_train = X_train.reshape(X_train.shape[0], H, W,1) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], H, W, 1)\n","  input_shape = ( H, W, 1) #채널이 앞으로 간다\n","\n","\n","# 전처리 2)scaling\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /=255\n","\n","\n","\n","# 전처리 3)one hot encoding\n","Y_train = np_utils.to_categorical(y_train)\n","Y_test = np_utils.to_categorical(y_test)\n","\n","\n","# 3. 모델 생성...\n","\n","\n","\n","model = keras.models.Sequential()\n","model.add(layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(64, (3,3), activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.25))\n","#위에서 나온 2차원 이미지 값들을 1차원으로 펼쳐서 FCN을 만든다\n","model.add(layers.Flatten())\n","model.add(layers.Dense(128, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","model.compile('rmsprop','categorical_crossentropy','accuracy')\n","\n","def plot_loss(history):\n","  plt.plot(history.history['loss'])\n","  plt.plot(history.history['val_loss'])\n","  plt.title('Model Loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","def plot_acc(history):\n","  plt.plot(history.history['accuracy'])\n","  plt.plot(history.history['val_accuracy'])\n","  plt.title('Model Accuracy')\n","  plt.ylabel('Accuracy')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","# 5. fit\n","history=model.fit(X_train, Y_train,epochs = 20, batch_size = 128, validation_split = 0.2)\n","score = model.evaluate(X_test, Y_test)\n","\n","# 6. \n","print(\"Test Loss : \",score[0])\n","print(\"Test Accuracy : \",score[1])\n","\n","plot_loss(history)\n","plot_acc(history)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PjQklcasqlz-"},"source":["plot_acc(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4dkgr_lTqq4p"},"source":["plot_loss(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tz9FEzBUq7Wo"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fY7nZ40_q1Mk"},"source":["#### 결론: \n","*   Test Loss :  0.3387230634689331, Test Accuracy :  0.9107999801635742\n","*   에폭이 증가할 수록 정확도는 매우 가파르게 증가..\n","*   어느 순간 validation set loss가 상승한다면 일반적으로 그 지점에서 훈련을 중단.\n","*   그 전에 훈련을 멈추면, 언더피팅인 상태고, 훈련을 더 계속하면 오버피팅 상태\n","*   padding=none일 경우 사이즈는..? (None, 26, 26, 32) > (None, 24, 24, 64) > (None, 24, 24, 64)  > (None, 12, 12, 64)  > (None, 9216) > (None, 128) > (None, 128) >  (None, 10)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"T2bDNTocsT2x"},"source":["###2. padding = 'same', epoch=20"]},{"cell_type":"code","metadata":{"id":"Gm1t3ZZ2qsPS"},"source":["import numpy as np\n","from keras import datasets\n","from keras import models, layers\n","from keras.utils import np_utils\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","\n","from keras import  backend\n"," \n","\n","# 1. DataLoader\n","(X_train, y_train),(X_test, y_test)=keras.datasets.fashion_mnist.load_data()\n","\n","# 2. 데이타 입력전 전처리과정 ---\n","# 1) 1차원으로 펼치기  2) /255   3)원핫인코딩\n","\n","L,H,W = X_train.shape # 3차원으로 출력된다...60000, 28, 28\n","\n","\n","# 전처리 1)\n","channel=backend.image_data_format()\n","channel\n","\n","if backend.image_data_format =='channels_first':\n","  X_train = X_train.reshape(X_train.shape[0],1, H, W) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], 1, H, W)\n","  input_shape = (1, H, W) #채널이 앞으로 간다\n","else:\n","  X_train = X_train.reshape(X_train.shape[0], H, W,1) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], H, W, 1)\n","  input_shape = ( H, W, 1) #채널이 앞으로 간다\n","\n","\n","# 전처리 2)scaling\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /=255\n","\n","\n","\n","# 전처리 3)one hot encoding\n","Y_train = np_utils.to_categorical(y_train)\n","Y_test = np_utils.to_categorical(y_test)\n","\n","\n","# 3. 모델 생성...\n","\n","\n","\n","model = keras.models.Sequential()\n","model.add(layers.Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.25))\n","#위에서 나온 2차원 이미지 값들을 1차원으로 펼쳐서 FCN을 만든다\n","model.add(layers.Flatten())\n","model.add(layers.Dense(128, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","model.compile('rmsprop','categorical_crossentropy','accuracy')\n","\n","def plot_loss(history):\n","  plt.plot(history.history['loss'])\n","  plt.plot(history.history['val_loss'])\n","  plt.title('Model Loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","def plot_acc(history):\n","  plt.plot(history.history['accuracy'])\n","  plt.plot(history.history['val_accuracy'])\n","  plt.title('Model Accuracy')\n","  plt.ylabel('Accuracy')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","# 5. fit\n","history=model.fit(X_train, Y_train,epochs = 20, batch_size = 128, validation_split = 0.2)\n","score = model.evaluate(X_test, Y_test)\n","\n","# 6. \n","print(\"Test Loss : \",score[0])\n","print(\"Test Accuracy : \",score[1])\n","\n","plot_loss(history)\n","plot_acc(history)\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ykaWCmlsiFa"},"source":["plot_acc(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dZR6MyEotOE3"},"source":["plot_loss(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IlZ_RXcYtRwa"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oj0-s49ouHiu"},"source":["#### 결론: \n","*   Test Loss :  0.3687363862991333, Test Accuracy :  0.9210000038146973\n","*   padding='same'일 경우, 아웃풋이 원래 인풋과 동일한 길이를 같도록 인풋을 패딩.\n","*   padding='valid'는 패딩 없음.\n","*   사이즈는 (None, 28, 28, 32) > (None, 28, 28, 64) > (None, 28, 28, 64)  > (None, 14, 14, 64)  > (None, 14, 14, 64) > (None, 12544) > (None, 128) > (None, 128) > (None, 10)"]},{"cell_type":"markdown","metadata":{"id":"URKUmsv-xhiG"},"source":["###3. padding = 'same', epoch=50"]},{"cell_type":"code","metadata":{"id":"fFEkD2FLuHTX"},"source":["import numpy as np\n","from keras import datasets\n","from keras import models, layers\n","from keras.utils import np_utils\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","\n","from keras import  backend\n"," \n","\n","# 1. DataLoader\n","(X_train, y_train),(X_test, y_test)=keras.datasets.fashion_mnist.load_data()\n","\n","# 2. 데이타 입력전 전처리과정 ---\n","# 1) 1차원으로 펼치기  2) /255   3)원핫인코딩\n","\n","L,H,W = X_train.shape # 3차원으로 출력된다...60000, 28, 28\n","\n","\n","# 전처리 1)\n","channel=backend.image_data_format()\n","channel\n","\n","if backend.image_data_format =='channels_first':\n","  X_train = X_train.reshape(X_train.shape[0],1, H, W) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], 1, H, W)\n","  input_shape = (1, H, W) #채널이 앞으로 간다\n","else:\n","  X_train = X_train.reshape(X_train.shape[0], H, W,1) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], H, W, 1)\n","  input_shape = ( H, W, 1) #채널이 앞으로 간다\n","\n","\n","# 전처리 2)scaling\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /=255\n","\n","\n","\n","# 전처리 3)one hot encoding\n","Y_train = np_utils.to_categorical(y_train)\n","Y_test = np_utils.to_categorical(y_test)\n","\n","\n","# 3. 모델 생성...\n","\n","\n","\n","model = keras.models.Sequential()\n","model.add(layers.Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.25))\n","#위에서 나온 2차원 이미지 값들을 1차원으로 펼쳐서 FCN을 만든다\n","model.add(layers.Flatten())\n","model.add(layers.Dense(128, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","model.compile('rmsprop','categorical_crossentropy','accuracy')\n","\n","def plot_loss(history):\n","  plt.plot(history.history['loss'])\n","  plt.plot(history.history['val_loss'])\n","  plt.title('Model Loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","def plot_acc(history):\n","  plt.plot(history.history['accuracy'])\n","  plt.plot(history.history['val_accuracy'])\n","  plt.title('Model Accuracy')\n","  plt.ylabel('Accuracy')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","# 5. fit\n","history=model.fit(X_train, Y_train,epochs = 50, batch_size = 128, validation_split = 0.2)\n","score = model.evaluate(X_test, Y_test)\n","\n","# 6. \n","print(\"Test Loss : \",score[0])\n","print(\"Test Accuracy : \",score[1])\n","\n","plot_loss(history)\n","plot_acc(history)\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3l4ogKUItZC8"},"source":["plot_acc(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tkrJImi9x3NA"},"source":["plot_loss(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jj46zyM6x5S9"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YLhDLh-7za2m"},"source":["#### 결론: \n","*   Test Loss :  0.3503759205341339,Test Accuracy :  0.9172999858856201\n","*   validation loss 그래프를 보았을 때, 약 13-16정도에서 validation loss가 급격히 증가함을 보아 이 때, 학습을 중단하는 것이 최선이 아닐까..?\n","*   fashion_mnist는 epoch만 증가시켰을 경우 Accuracy의 증가는 뚜렷하지 않음. "]},{"cell_type":"markdown","metadata":{"id":"VveHX4GB0est"},"source":["###3. padding = 'same', epoch=16"]},{"cell_type":"code","metadata":{"id":"iZ7Q_ATP0bJa"},"source":["import numpy as np\n","from keras import datasets\n","from keras import models, layers\n","from keras.utils import np_utils\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","\n","from keras import  backend\n"," \n","\n","# 1. DataLoader\n","(X_train, y_train),(X_test, y_test)=keras.datasets.fashion_mnist.load_data()\n","\n","# 2. 데이타 입력전 전처리과정 ---\n","# 1) 1차원으로 펼치기  2) /255   3)원핫인코딩\n","\n","L,H,W = X_train.shape # 3차원으로 출력된다...60000, 28, 28\n","\n","\n","# 전처리 1)\n","channel=backend.image_data_format()\n","channel\n","\n","if backend.image_data_format =='channels_first':\n","  X_train = X_train.reshape(X_train.shape[0],1, H, W) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], 1, H, W)\n","  input_shape = (1, H, W) #채널이 앞으로 간다\n","else:\n","  X_train = X_train.reshape(X_train.shape[0], H, W,1) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], H, W, 1)\n","  input_shape = ( H, W, 1) #채널이 앞으로 간다\n","\n","\n","# 전처리 2)scaling\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /=255\n","\n","\n","\n","# 전처리 3)one hot encoding\n","Y_train = np_utils.to_categorical(y_train)\n","Y_test = np_utils.to_categorical(y_test)\n","\n","\n","# 3. 모델 생성...\n","\n","\n","\n","model = keras.models.Sequential()\n","model.add(layers.Conv2D(32, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.25))\n","#위에서 나온 2차원 이미지 값들을 1차원으로 펼쳐서 FCN을 만든다\n","model.add(layers.Flatten())\n","model.add(layers.Dense(128, activation='relu'))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","model.compile('rmsprop','categorical_crossentropy','accuracy')\n","\n","def plot_loss(history):\n","  plt.plot(history.history['loss'])\n","  plt.plot(history.history['val_loss'])\n","  plt.title('Model Loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","def plot_acc(history):\n","  plt.plot(history.history['accuracy'])\n","  plt.plot(history.history['val_accuracy'])\n","  plt.title('Model Accuracy')\n","  plt.ylabel('Accuracy')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","# 5. fit\n","history=model.fit(X_train, Y_train,epochs = 16, batch_size = 128, validation_split = 0.2)\n","score = model.evaluate(X_test, Y_test)\n","\n","# 6. \n","print(\"Test Loss : \",score[0])\n","print(\"Test Accuracy : \",score[1])\n","\n","plot_loss(history)\n","plot_acc(history)\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ltsQJMPp0iZg"},"source":["plot_acc(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-U_Pv1Je1EeK"},"source":["plot_loss(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y7W_kARs1HAI"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NpY3QmrZ3XC9"},"source":["#### 결론: \n","*   Test Loss :  0.2769700586795807, Test Accuracy :  0.9160000085830688\n","*   validation loss 그래프를 보았을 때, 약 13-16정도에서 validation loss가 급격히 증가함을 보아 이 때, 학습을 중단하는 것이 최선이 아닐까..?..했지만 epoch=20일 때가 더 정확도가 좋으므로 20으로하자.\n","*   더 높이기위해 layer 수를 늘려보자."]},{"cell_type":"markdown","metadata":{"id":"sDw32NBV4dAt"},"source":["###4. padding = 'same', epoch=20, layer 수 증가 및 dropout 변경"]},{"cell_type":"code","metadata":{"id":"3wTvu5QU4ZEo"},"source":["import numpy as np\n","from keras import datasets\n","from keras import models, layers\n","from keras.utils import np_utils\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","\n","from keras import  backend\n"," \n","\n","# 1. DataLoader\n","(X_train, y_train),(X_test, y_test)=keras.datasets.fashion_mnist.load_data()\n","\n","# 2. 데이타 입력전 전처리과정 ---\n","# 1) 1차원으로 펼치기  2) /255   3)원핫인코딩\n","\n","L,H,W = X_train.shape # 3차원으로 출력된다...60000, 28, 28\n","\n","\n","# 전처리 1)\n","channel=backend.image_data_format()\n","channel\n","\n","if backend.image_data_format =='channels_first':\n","  X_train = X_train.reshape(X_train.shape[0],1, H, W) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], 1, H, W)\n","  input_shape = (1, H, W) #채널이 앞으로 간다\n","else:\n","  X_train = X_train.reshape(X_train.shape[0], H, W,1) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], H, W, 1)\n","  input_shape = ( H, W, 1) #채널이 앞으로 간다\n","\n","\n","# 전처리 2)scaling\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /=255\n","\n","\n","\n","# 전처리 3)one hot encoding\n","Y_train = np_utils.to_categorical(y_train)\n","Y_test = np_utils.to_categorical(y_test)\n","\n","\n","# 3. 모델 생성...\n","\n","\n","\n","model = keras.models.Sequential()\n","model.add(layers.Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.1))\n","\n","model.add(layers.Conv2D(128, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.2))\n","\n","model.add(layers.Conv2D(256, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(256, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.3))\n","\n","#위에서 나온 2차원 이미지 값들을 1차원으로 펼쳐서 FCN을 만든다\n","model.add(layers.Flatten())\n","model.add(layers.Dense(1024, activation='relu'))\n","model.add(layers.Dropout(0.3))\n","model.add(layers.Dense(512, activation='relu'))\n","model.add(layers.Dropout(0.4))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","model.compile('rmsprop','categorical_crossentropy','accuracy')\n","\n","def plot_loss(history):\n","  plt.plot(history.history['loss'])\n","  plt.plot(history.history['val_loss'])\n","  plt.title('Model Loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","def plot_acc(history):\n","  plt.plot(history.history['accuracy'])\n","  plt.plot(history.history['val_accuracy'])\n","  plt.title('Model Accuracy')\n","  plt.ylabel('Accuracy')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","# 5. fit\n","history=model.fit(X_train, Y_train,epochs = 16, batch_size = 128, validation_split = 0.2)\n","score = model.evaluate(X_test, Y_test)\n","\n","# 6. \n","print(\"Test Loss : \",score[0])\n","print(\"Test Accuracy : \",score[1])\n","\n","plot_loss(history)\n","plot_acc(history)\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gWdVCmq56OvF"},"source":["plot_acc(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CwhDQ76S6RkP"},"source":["plot_loss(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N33rrjXR6T0s"},"source":["model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mhyOyZeK73_e"},"source":["#### 결론: \n","*   Epoch=12면 어떻게 되려나.."]},{"cell_type":"markdown","metadata":{"id":"w9I6ziDO8CSZ"},"source":["###5. 4와 동일하게 하고 epoch=12로"]},{"cell_type":"code","metadata":{"id":"YoHp0bqp7-fi"},"source":["import numpy as np\n","from keras import datasets\n","from keras import models, layers\n","from keras.utils import np_utils\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","\n","from keras import  backend\n"," \n","\n","# 1. DataLoader\n","(X_train, y_train),(X_test, y_test)=keras.datasets.fashion_mnist.load_data()\n","\n","# 2. 데이타 입력전 전처리과정 ---\n","# 1) 1차원으로 펼치기  2) /255   3)원핫인코딩\n","\n","L,H,W = X_train.shape # 3차원으로 출력된다...60000, 28, 28\n","\n","\n","# 전처리 1)\n","channel=backend.image_data_format()\n","channel\n","\n","if backend.image_data_format =='channels_first':\n","  X_train = X_train.reshape(X_train.shape[0],1, H, W) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], 1, H, W)\n","  input_shape = (1, H, W) #채널이 앞으로 간다\n","else:\n","  X_train = X_train.reshape(X_train.shape[0], H, W,1) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], H, W, 1)\n","  input_shape = ( H, W, 1) #채널이 앞으로 간다\n","\n","\n","# 전처리 2)scaling\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /=255\n","\n","\n","\n","# 전처리 3)one hot encoding\n","Y_train = np_utils.to_categorical(y_train)\n","Y_test = np_utils.to_categorical(y_test)\n","\n","\n","# 3. 모델 생성...\n","\n","\n","\n","model = keras.models.Sequential()\n","model.add(layers.Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.1))\n","\n","model.add(layers.Conv2D(128, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.2))\n","\n","model.add(layers.Conv2D(256, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(256, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.3))\n","\n","#위에서 나온 2차원 이미지 값들을 1차원으로 펼쳐서 FCN을 만든다\n","model.add(layers.Flatten())\n","model.add(layers.Dense(1024, activation='relu'))\n","model.add(layers.Dropout(0.3))\n","model.add(layers.Dense(512, activation='relu'))\n","model.add(layers.Dropout(0.4))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","model.compile('rmsprop','categorical_crossentropy','accuracy')\n","\n","def plot_loss(history):\n","  plt.plot(history.history['loss'])\n","  plt.plot(history.history['val_loss'])\n","  plt.title('Model Loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","def plot_acc(history):\n","  plt.plot(history.history['accuracy'])\n","  plt.plot(history.history['val_accuracy'])\n","  plt.title('Model Accuracy')\n","  plt.ylabel('Accuracy')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","# 5. fit\n","history=model.fit(X_train, Y_train,epochs = 12, batch_size = 128, validation_split = 0.2)\n","score = model.evaluate(X_test, Y_test)\n","\n","# 6. \n","print(\"Test Loss : \",score[0])\n","print(\"Test Accuracy : \",score[1])\n","\n","plot_loss(history)\n","plot_acc(history)\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LRXtATad8J8z"},"source":["plot_acc(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MI3RBr9y8NPm"},"source":["plot_loss(history)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R8wJ6vXZ_Dz-"},"source":["#### 결론: \n","*   Test Loss :  0.2834482491016388, Test Accuracy :  0.9200000166893005\n","*   epoch=12로 고정해보고 "]},{"cell_type":"markdown","metadata":{"id":"oQd9v2ky_4ov"},"source":["###6. imageAugmentation 추가.."]},{"cell_type":"code","metadata":{"id":"YyWWtPyE8SsX"},"source":["import numpy as np\n","from keras import datasets\n","from keras import models, layers\n","from keras.utils import np_utils\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","\n","from keras import  backend\n"," \n","\n","# 1. DataLoader\n","(X_train, y_train),(X_test, y_test)=keras.datasets.fashion_mnist.load_data()\n","\n","# 2. 데이타 입력전 전처리과정 ---\n","# 1) 1차원으로 펼치기  2) /255   3)원핫인코딩\n","\n","L,H,W = X_train.shape # 3차원으로 출력된다...60000, 28, 28\n","\n","\n","# 전처리 1)\n","channel=backend.image_data_format()\n","channel\n","\n","if backend.image_data_format =='channels_first':\n","  X_train = X_train.reshape(X_train.shape[0],1, H, W) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], 1, H, W)\n","  input_shape = (1, H, W) #채널이 앞으로 간다\n","else:\n","  X_train = X_train.reshape(X_train.shape[0], H, W,1) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], H, W, 1)\n","  input_shape = ( H, W, 1) #채널이 앞으로 간다\n","\n","\n","# 전처리 2)scaling\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /=255\n","\n","\n","\n","# 전처리 3)one hot encoding\n","Y_train = np_utils.to_categorical(y_train)\n","Y_test = np_utils.to_categorical(y_test)\n","\n","\n","# 3. 모델 생성...\n","\n","\n","\n","model = keras.models.Sequential()\n","model.add(layers.Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.1))\n","\n","model.add(layers.Conv2D(128, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.2))\n","\n","model.add(layers.Conv2D(256, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(256, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.3))\n","\n","#위에서 나온 2차원 이미지 값들을 1차원으로 펼쳐서 FCN을 만든다\n","model.add(layers.Flatten())\n","model.add(layers.Dense(1024, activation='relu'))\n","model.add(layers.Dropout(0.3))\n","model.add(layers.Dense(512, activation='relu'))\n","model.add(layers.Dropout(0.4))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","model.compile('rmsprop','categorical_crossentropy','accuracy')\n","\n","def plot_loss(history):\n","  plt.plot(history.history['loss'])\n","  plt.plot(history.history['val_loss'])\n","  plt.title('Model Loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","def plot_acc(history):\n","  plt.plot(history.history['accuracy'])\n","  plt.plot(history.history['val_accuracy'])\n","  plt.title('Model Accuracy')\n","  plt.ylabel('Accuracy')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","# 5. fit\n","history=model.fit(X_train, Y_train,epochs = 12, batch_size = 128, validation_split = 0.2)\n","score = model.evaluate(X_test, Y_test)\n","\n","# 6. \n","print(\"Test Loss : \",score[0])\n","print(\"Test Accuracy : \",score[1])\n","\n","plot_loss(history)\n","plot_acc(history)\n","plt.show()\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lDBNljf-AJKB"},"source":["plot_acc(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iZHsW0-WAJCX"},"source":["plot_loss(history)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wuxXord6BL0K"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"kKf78VCfBNbW"},"source":[""]},{"cell_type":"code","metadata":{"id":"Ql8Pw6ClBMkU"},"source":["import numpy as np\n","from keras import datasets\n","from keras import models, layers\n","from keras.utils import np_utils\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","\n","from keras import  backend\n"," \n","\n","# 1. DataLoader\n","(X_train, y_train),(X_test, y_test)=keras.datasets.fashion_mnist.load_data()\n","\n","# 2. 데이타 입력전 전처리과정 ---\n","# 1) 1차원으로 펼치기  2) /255   3)원핫인코딩\n","\n","L,H,W = X_train.shape # 3차원으로 출력된다...60000, 28, 28\n","\n","\n","# 전처리 1)\n","channel=backend.image_data_format()\n","channel\n","\n","if backend.image_data_format =='channels_first':\n","  X_train = X_train.reshape(X_train.shape[0],1, H, W) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], 1, H, W)\n","  input_shape = (1, H, W) #채널이 앞으로 간다\n","else:\n","  X_train = X_train.reshape(X_train.shape[0], H, W,1) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], H, W, 1)\n","  input_shape = ( H, W, 1) #채널이 앞으로 간다\n","\n","\n","# 전처리 2)scaling\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /=255\n","\n","\n","\n","# 전처리 3)one hot encoding\n","Y_train = np_utils.to_categorical(y_train)\n","Y_test = np_utils.to_categorical(y_test)\n","\n","\n","\n","\n","# 3. 모델 생성...\n","\n","\n","\n","model = keras.models.Sequential()\n","model.add(layers.Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.1))\n","\n","model.add(layers.Conv2D(128, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.2))\n","\n","model.add(layers.Conv2D(256, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(256, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.3))\n","\n","#위에서 나온 2차원 이미지 값들을 1차원으로 펼쳐서 FCN을 만든다\n","model.add(layers.Flatten())\n","model.add(layers.Dense(1024, activation='relu'))\n","model.add(layers.Dropout(0.3))\n","model.add(layers.Dense(512, activation='relu'))\n","model.add(layers.Dropout(0.4))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","model.compile('rmsprop','categorical_crossentropy','accuracy')\n","\n","def plot_loss(history):\n","  plt.plot(history.history['loss'])\n","  plt.plot(history.history['val_loss'])\n","  plt.title('Model Loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","def plot_acc(history):\n","  plt.plot(history.history['accuracy'])\n","  plt.plot(history.history['val_accuracy'])\n","  plt.title('Model Accuracy')\n","  plt.ylabel('Accuracy')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","# 5. fit\n","history=model.fit(X_train, Y_train,epochs = 30, batch_size = 128, validation_split = 0.2)\n","score = model.evaluate(X_test, Y_test)\n","\n","# 6. \n","print(\"Test Loss : \",score[0])\n","print(\"Test Accuracy : \",score[1])\n","\n","plot_loss(history)\n","plot_acc(history)\n","plt.show()\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xjP6rio_BM56"},"source":["plot_loss(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_h3AUJOBVtg"},"source":["plot_acc(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SSrCYAoUBVrG"},"source":["import numpy as np\n","from keras import datasets\n","from keras import models, layers\n","from keras.utils import np_utils\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","\n","from keras import  backend\n"," \n","\n","# 1. DataLoader\n","(X_train, y_train),(X_test, y_test)=keras.datasets.fashion_mnist.load_data()\n","\n","# 2. 데이타 입력전 전처리과정 ---\n","# 1) 1차원으로 펼치기  2) /255   3)원핫인코딩\n","\n","L,H,W = X_train.shape # 3차원으로 출력된다...60000, 28, 28\n","\n","\n","# 전처리 1)\n","channel=backend.image_data_format()\n","channel\n","\n","if backend.image_data_format =='channels_first':\n","  X_train = X_train.reshape(X_train.shape[0],1, H, W) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], 1, H, W)\n","  input_shape = (1, H, W) #채널이 앞으로 간다\n","else:\n","  X_train = X_train.reshape(X_train.shape[0], H, W,1) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], H, W, 1)\n","  input_shape = ( H, W, 1) #채널이 앞으로 간다\n","\n","\n","# 전처리 2)scaling\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /=255\n","\n","\n","\n","# 전처리 3)one hot encoding\n","Y_train = np_utils.to_categorical(y_train)\n","Y_test = np_utils.to_categorical(y_test)\n","\n","datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    featurewise_center=True,\n","    featurewise_std_normalization=True,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    horizontal_flip=True,\n","    zca_whitening=True)\n","\n","\n","# 3. 모델 생성...\n","\n","\n","\n","model = keras.models.Sequential()\n","model.add(layers.Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.1))\n","\n","model.add(layers.Conv2D(128, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.2))\n","\n","model.add(layers.Conv2D(256, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(256, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.3))\n","\n","#위에서 나온 2차원 이미지 값들을 1차원으로 펼쳐서 FCN을 만든다\n","model.add(layers.Flatten())\n","model.add(layers.Dense(1024, activation='relu'))\n","model.add(layers.Dropout(0.3))\n","model.add(layers.Dense(512, activation='relu'))\n","model.add(layers.Dropout(0.4))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","model.compile('rmsprop','categorical_crossentropy','accuracy')\n","\n","def plot_loss(history):\n","  plt.plot(history.history['loss'])\n","  plt.plot(history.history['val_loss'])\n","  plt.title('Model Loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","def plot_acc(history):\n","  plt.plot(history.history['accuracy'])\n","  plt.plot(history.history['val_accuracy'])\n","  plt.title('Model Accuracy')\n","  plt.ylabel('Accuracy')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","# 5. fit\n","history=model.fit(X_train, Y_train,epochs = 40, batch_size = 128, validation_split = 0.2)\n","score = model.evaluate(X_test, Y_test)\n","\n","# 6. \n","print(\"Test Loss : \",score[0])\n","print(\"Test Accuracy : \",score[1])\n","\n","plot_loss(history)\n","plot_acc(history)\n","plt.show()\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xFuLlN3IBVoV"},"source":["plot_loss(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zycMBVIqBZR8"},"source":["plot_acc(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yJ-tWEeIBZO9"},"source":["import numpy as np\n","from keras import datasets\n","from keras import models, layers\n","from keras.utils import np_utils\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","\n","from keras import  backend\n"," \n","\n","# 1. DataLoader\n","(X_train, y_train),(X_test, y_test)=keras.datasets.fashion_mnist.load_data()\n","\n","# 2. 데이타 입력전 전처리과정 ---\n","# 1) 1차원으로 펼치기  2) /255   3)원핫인코딩\n","\n","L,H,W = X_train.shape # 3차원으로 출력된다...60000, 28, 28\n","\n","\n","# 전처리 1)\n","channel=backend.image_data_format()\n","channel\n","\n","if backend.image_data_format =='channels_first':\n","  X_train = X_train.reshape(X_train.shape[0],1, H, W) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], 1, H, W)\n","  input_shape = (1, H, W) #채널이 앞으로 간다\n","else:\n","  X_train = X_train.reshape(X_train.shape[0], H, W,1) # X_train[0] 대신에 -1써도 동일한 표현\n","  X_test = X_test.reshape(X_test.shape[0], H, W, 1)\n","  input_shape = ( H, W, 1) #채널이 앞으로 간다\n","\n","\n","# 전처리 2)scaling\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /=255\n","\n","\n","\n","# 전처리 3)one hot encoding\n","Y_train = np_utils.to_categorical(y_train)\n","Y_test = np_utils.to_categorical(y_test)\n","\n","datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","    featurewise_center=True,\n","    featurewise_std_normalization=True,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    horizontal_flip=True,\n","    zca_whitening=True)\n","\n","\n","# 3. 모델 생성...\n","\n","\n","\n","model = keras.models.Sequential()\n","model.add(layers.Conv2D(64, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(64, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.1))\n","\n","model.add(layers.Conv2D(128, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(128, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.2))\n","\n","model.add(layers.Conv2D(256, kernel_size=(3,3), padding='same', activation='relu', input_shape = input_shape))\n","model.add(layers.Conv2D(256, (3,3), padding='same', activation='relu'))\n","model.add(layers.BatchNormalization())\n","model.add(layers.MaxPool2D(pool_size=(2,2)))\n","model.add(layers.Dropout(0.3))\n","\n","#위에서 나온 2차원 이미지 값들을 1차원으로 펼쳐서 FCN을 만든다\n","model.add(layers.Flatten())\n","model.add(layers.Dense(1024, activation='relu'))\n","model.add(layers.Dropout(0.3))\n","model.add(layers.Dense(512, activation='relu'))\n","model.add(layers.Dropout(0.4))\n","model.add(layers.Dense(10, activation='softmax'))\n","\n","model.compile('rmsprop','categorical_crossentropy','accuracy')\n","\n","def plot_loss(history):\n","  plt.plot(history.history['loss'])\n","  plt.plot(history.history['val_loss'])\n","  plt.title('Model Loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","def plot_acc(history):\n","  plt.plot(history.history['accuracy'])\n","  plt.plot(history.history['val_accuracy'])\n","  plt.title('Model Accuracy')\n","  plt.ylabel('Accuracy')\n","  plt.xlabel('Epoch')\n","  plt.legend(['Train','Validation'])\n","\n","# 5. fit\n","history=model.fit(X_train, Y_train,epochs = 50, batch_size = 128, validation_split = 0.2)\n","score = model.evaluate(X_test, Y_test)\n","\n","# 6. \n","print(\"Test Loss : \",score[0])\n","print(\"Test Accuracy : \",score[1])\n","\n","plot_loss(history)\n","plot_acc(history)\n","plt.show()\n","\n","\n"],"execution_count":null,"outputs":[]}]}