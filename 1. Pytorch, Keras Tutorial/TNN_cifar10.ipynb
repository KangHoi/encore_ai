{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TNN_cifar10.ipynb","private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyP7+Lh92SPPdAxSPZvvvQRy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xqDV6038kWdB"},"source":["import torch\n","import torchvision\n","import torch.nn as nn \n","import torch.nn.init\n","import numpy as np\n","import torchvision.transforms as transforms \n","import matplotlib.pyplot as plt\n","\n","#디버깅 모듈 설치\n","import pdb\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rRsFONGvkfIq"},"source":["#우리가 사용할 컴퓨터를 check하는 부분, cpu/gpu 지원받을지..\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","device"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QpbD-hrpkgCu"},"source":["# 하이퍼파라미터 설정\n","\n","input_size = 3072 # mnist는 32*32*3로 구성\n","hidden_size = 500 # 은닉층의 unit 수\n","num_classes = 10 # 카테고리 개수\n","num_epochs = 5\n","batch_size = 100\n","learning_rate = 0.001\n","\n","# dataset 로딩 - 2개의 과정을 거친다\n","# train_dataset, test_dataset 데이터 로딩 1단계\n","train_dataset = torchvision.datasets.CIFAR10(root='../../data',\n","                                           train = True, #traindataset만 저장\n","                                           transform = transforms.ToTensor(),\n","                                           download = True) #traindataset을 스케일링하여 다운로드하겠다.\n","test_dataset = torchvision.datasets.CIFAR10(root='../../data',\n","                                           train = False, #test_dataset만 저장, test옵션은 따로 없음.\n","                                           transform = transforms.ToTensor())\n","\n","# 데이터 로딩 2단계.. BatchSize 이용\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size = batch_size,\n","                                           shuffle =True)\n","\n","# 100개씩 쪼개서 저장..\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n","                                           batch_size = batch_size,\n","                                           shuffle =False) #테스트는 학습이아니므로 shuffle 필요 없다."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w8-FnK1Rk2qY"},"source":["class ConvNet(nn.Module):\n","  def __init__(self, num_classes=10):\n","    super(ConvNet, self).__init__()\n","\n","        # L1 ImgIn shape=(?, 32, 32, 3)\n","        #    Conv     -> (?, 32, 32, 32)\n","        #    Pool     -> (?, 16, 16, 32)\n","    self.layer1 =nn.Sequential(\n","        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(32),#\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2, stride=2))\n","\n","        \n","        \n","        # L2 ImgIn shape=(?, 16, 16, 32)\n","        #    Conv     -> (?, 16, 16, 64)\n","        #    Pool     -> (?, 8, 8, 64)   \n","    self.layer2 = nn.Sequential(\n","        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(64), #\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2, stride=2))\n","    \n","\n","        # L3 ImgIn shape=(?, 8, 8, 64)\n","        #    Conv     -> (?, 8, 8, 128)\n","        #    Pool     -> (?, 4, 4, 128)   \n","    self.layer3 = nn.Sequential(\n","        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(128), #\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","\n","    #     # L3 ImgIn shape=(?, 8, 8, 64)\n","    #     #    Conv     -> (?, 8, 8, 128)\n","    #     #    Pool     -> (?, 4, 4, 128)   \n","    # self.layer4 = nn.Sequential(\n","    #     nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n","    #     nn.BatchNorm2d(256), #\n","    #     nn.ReLU(),\n","    #     nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","\n","    self.fc1 = torch.nn.Linear(4*4*128, 625, bias=True)\n","    torch.nn.init.xavier_uniform_(self.fc1.weight)\n","    self.layer3 = torch.nn.Sequential(\n","        self.fc1,\n","        torch.nn.ReLU(),\n","        torch.nn.Dropout(p=1 - self.keep_prob))\n","    # L5 Final FC 625 inputs -> 10 outputs\n","    self.fc2 = torch.nn.Linear(625, num_classes,  bias=True)\n","    torch.nn.init.xavier_uniform_(self.fc2.weight)\n","\n","  def forward(self, x):\n","\n","    # pdb.set_trace() # 2.디버깅\n","        # n : 다음 라인 가르킨다.\n","        # x.size, out.size  등 크기 확인 필요\n","\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = out.view(out.size(0), -1)   # Flatten them for FC\n","        out = self.layer3(out)\n","        out = self.fc2(out)\n","        return out\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MroTbLBAlxnO"},"source":["model = ConvNet(num_classes).to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ide6e3Wfl392"},"source":["loss_function = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VYZ_PjnGl5zu"},"source":["total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        # pdb.set_trace() # 1. 디버깅.. 주석으로 막아두고 후에 사용.. outputs에서 호출되며 실행 \n","         \n","        # l : pdb로 어느부분을 디버깅 하려 하는지 알 수 있음.. 호출되는 함수인 forward가 나타남.\n","        # images.size(), images.shape : 이미지 사이즈 알아보기([batch_size, channel, height, width])\n","        # labels.size() : 라벨의 사이즈 알 수 있다.\n","        # labels : 라벨을 전부 뽑는다.\n","        # quit, q : 빠져나온다. 빠져나오면서 error 나오지만 신경 안써도됨.\n","        \n","\n","        \n","\n","        outputs = model(images) # =model.forward(images)...모델에 입력값을 넣어 예측값을 반환. 이때 forward함수 호출.\n","        \n","        loss = loss_function\n","\n","        # pdb.set_trace() #3.디버깅\n","            # loss값 확인 가능. loss.item()..\n","        n(outputs, labels)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if(i+1) % 100 ==0:\n","            print('Epoch[{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"maerEuJSl7-g"},"source":[""],"execution_count":null,"outputs":[]}]}