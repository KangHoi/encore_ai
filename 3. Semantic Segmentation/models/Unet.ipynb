{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Unet.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"l7KEMiRkHLln"},"source":["'''\n","이 코드는 조금 쉽게 작성한 UNet 모델. 더 어렵게 작성도 가능\n","하지만 공통적인 부분은 큰 틀에서 거의 동일\n","\n","큰 틀을 보면,\n","1. 메인 모델 클래스 정의\n","    class UNet(nn.Module):\n","2. 메인 모델 클래스에서 사용할 서브 모듈을 정의해 놓는다.\n","    class DoubleConv(nn.Module): --> Conv2d + BatchNormd + ReLU 이게 2번 반복\n","    class Down(nn.Mdule): --> stride =2를 사용해 사이즈를 정확하게 반으로 줄임\n","    class Up(nn.Module): --> stride=1이 지정됨. 사이즈 2배 늘림.. interpolation 방법으로 늘리고.. concat 사용.. \n","    100,3,28,28 = (배치, 채널, H, W) dim=1은 채널을 중심으로 붙이자.\n","\n","\n","여기서 한가지!!\n","자주 사용하는 코드들은 당연히 모듈화 시켜놓고\n","필요할 때 함수를 호출해서 재사용성을 높인다.\n","모델 클래스를 작성할 때\n","딱 이 2가지 패턴으로 작성한다.\n","1. 지금처럼 코드 안에 서브 모듈을 정의해서 바로 사용하는 경우\n","2. module.py로 빼놓고 거기서 뽑아쓰는 방법... 확인\n","\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sCN_iC0cHZmg"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pdb\n","\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=1):\n","        super().__init__()\n","        assert stride in [1, 2]\n","        self.double_conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True))\n","\n","    def forward(self, x):\n","        return self.double_conv(x)\n","\n","\n","class Down(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv = nn.Sequential(\n","            DoubleConv(in_channels, out_channels, stride=2))\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        return x\n","\n","\n","class Up(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv = DoubleConv(in_channels, out_channels)\n","\n","    def forward(self, x1, x2):\n","        # pdb.set_trace()\n","        h, w = x1.size()[2:]\n","        x1 = F.interpolate(x1, (h*2,w*2)) # 사이즈 두배 늘리는 보간법\n","        x = torch.cat([x2, x1], dim=1) # dim=1.. 채널을 기준으로 concat.. 뒤로 채널수가 늘게 concat된다.\n","        return self.conv(x)\n","\n","\n","class UNet(nn.Module): # UNet : main model 클래스 이름\n","    def __init__(self, classes, model):\n","        super(UNet, self).__init__()\n","        # 해당 네트워크의 기본 채널이 지정된다.\n","        if model == 'unet32': # 가벼운 모델.. 성능은 다소 아쉬워도 속도가 중요\n","            base_channels=32\n","        elif model == 'unet64':\n","            base_channels=64\n","        elif model == 'unet128': # 무거운 모델.. 위와 반대.. 성능이 어느정도 보장.. 코드 작성하는 사람의 자율도\n","            base_channels=128\n","        else: # 이 밖의 채널이 들어오면 에러\n","            raise ValueError(f'{model} is not supported model')\n","\n","        # unet에서 사용할 모듈 다시 지정..\n","        # - class DoubleConv : Conv2d, BatchNormalization, ReLU\n","        # - class Down : 입력사이즈를 절반으로 줄인다. stride=2사용\n","        # - class Up : 사이즈를 2배로 늘린다. interpolate(보간법), concat 실행\n","\n","\n","        self.inc   = DoubleConv(3, base_channels) # Assume input has 3 channels\n","        self.down1 = Down(base_channels, base_channels*2) # 32 ---> 64\n","        self.down2 = Down(base_channels*2, base_channels*4) # 64 ---> 128\n","        self.down3 = Down(base_channels*4, base_channels*8) # 128 ---> 256\n","        self.down4 = Down(base_channels*8, base_channels*8) # 256 ---> 256\n","        # 여기까지가 downsampling = convolution = encoding.. 특징 추출\n","\n","        # 아래부터 upsampling .. 채널 준다\n","        self.up1   = Up(base_channels*16, base_channels*4) # 512 ---> 128\n","        self.up2   = Up(base_channels*8, base_channels*2) # 256 ---> 64\n","        self.up3   = Up(base_channels*4, base_channels) # 128 ---> 32\n","        self.up4   = Up(base_channels*2, base_channels) # 64---> 32\n","        self.outc  = nn.Conv2d(base_channels, classes, kernel_size=1) # 32--->2\n","\n","    def forward(self, x):\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1)\n","        x3 = self.down2(x2)\n","        x4 = self.down3(x3)\n","        x5 = self.down4(x4)\n","        x = self.up1(x5, x4)\n","        x = self.up2(x, x3)\n","        x = self.up3(x, x2)\n","        x = self.up4(x, x1)\n","        x = self.outc(x)\n","        return x\n","\n","\n","if __name__ == \"__main__\":\n","    import pdb\n","\n","    model = UNet(2, 'unet128').cuda()\n","    x = torch.rand(4,3,256,256).cuda()\n","    y = model(x)\n","    print(y.size())"],"execution_count":null,"outputs":[]}]}